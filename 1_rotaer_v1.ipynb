{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\julia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.25.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\julia\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install PyMuPDF\n",
    "%pip install PyPDF2\n",
    "import re\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler pdf\n",
    "\n",
    "def ler_pdf_para_dataframe(nome_arquivo):\n",
    "    try:\n",
    "        # Abrir o PDF\n",
    "        pdf_document = fitz.open(nome_arquivo)\n",
    "        dados = []\n",
    "\n",
    "        # Ler todas as páginas e armazenar o texto em uma lista\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            text = page.get_text(\"text\")  # Extração de texto\n",
    "            dados.append({\"Página\": page_num + 1, \"Texto\": text})\n",
    "\n",
    "        # Fechar o documento\n",
    "        pdf_document.close()\n",
    "        \n",
    "        # Criar DataFrame com os textos extraídos\n",
    "        df = pd.DataFrame(dados)\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao abrir o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Nome do arquivo PDF\n",
    "nome_arquivo = \"data/pdf/rotaer_completo.pdf\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorrências de 'RDONAV': 144\n",
      "Ocorrências de 'RFFS': 174\n",
      "Ocorrências de 'D-AMDT': 6273\n"
     ]
    }
   ],
   "source": [
    "#contar a quantidade de avezes de aparecimento dos termos\n",
    "\n",
    "# Nome do arquivo PDF\n",
    "nome_arquivo = \"data/pdf/rotaer_completo.pdf\"\n",
    "\n",
    "def contar_termos_pdf(nome_arquivo):\n",
    "    try:\n",
    "        # Abrir o PDF\n",
    "        pdf_document = fitz.open(nome_arquivo)\n",
    "        texto_completo = \"\"\n",
    "\n",
    "        # Ler todas as páginas e armazenar o texto\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            texto_completo += page.get_text(\"text\") + \"\\n\"  # Concatenar todo o texto\n",
    "\n",
    "        # Fechar o documento\n",
    "        pdf_document.close()\n",
    "\n",
    "        # Contar as ocorrências dos termos no texto completo\n",
    "        contagem_rdonav = len(re.findall(r'\\bRDONAV\\b', texto_completo, re.IGNORECASE))\n",
    "        contagem_rffs = len(re.findall(r'\\bRFFS\\b', texto_completo, re.IGNORECASE))\n",
    "        contagem_d_amdt = len(re.findall(r'\\bD-AMDT\\b', texto_completo, re.IGNORECASE))\n",
    "\n",
    "        return {\n",
    "            \"RDONAV\": contagem_rdonav,\n",
    "            \"RFFS\": contagem_rffs,\n",
    "            \"D-AMDT\": contagem_d_amdt\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o arquivo '{nome_arquivo}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Contar os termos no PDF\n",
    "contagem_termos = contar_termos_pdf(nome_arquivo)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(f\"Ocorrências de 'RDONAV': {contagem_termos['RDONAV']}\")\n",
    "print(f\"Ocorrências de 'RFFS': {contagem_termos['RFFS']}\")\n",
    "print(f\"Ocorrências de 'D-AMDT': {contagem_termos['D-AMDT']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo dos códigos capturados:\n",
      "codigo_aeroporto\n",
      "SJOQ    2\n",
      "SJUR    2\n",
      "SWGN    2\n",
      "SDOX    2\n",
      "SN9Z    2\n",
      "       ..\n",
      "SSZD    1\n",
      "SJI9    1\n",
      "SNBC    1\n",
      "SD9P    1\n",
      "SS7W    1\n",
      "Name: count, Length: 5675, dtype: int64\n",
      "\n",
      "✅ SBGR foi capturado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#CRIAR BASE DE CODIGO OACI+ INFO ROTAER \n",
    "\n",
    "def extrair_dados_pdf(nome_arquivo):\n",
    "    try:\n",
    "        pdf_document = fitz.open(nome_arquivo)\n",
    "        texto_completo = []\n",
    "\n",
    "        # Ler todas as páginas e armazenar o texto\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            text = page.get_text(\"text\")\n",
    "            texto_completo.extend(text.split(\"\\n\"))\n",
    "\n",
    "        pdf_document.close()\n",
    "\n",
    "        dados_aeroportos = []\n",
    "        capturando = False\n",
    "        aeroporto_info = []\n",
    "        codigo_oaci = None\n",
    "\n",
    "        # Regex que procura o OACI entre parênteses com espaço antes e depois\n",
    "        regex_oaci = r\"\\(\\s*([S][A-Z0-9]{3})\\s*\\)\"\n",
    "\n",
    "        linhas_espera_oaci = 0  # Contador de linhas após o D-AMDT\n",
    "        linha_damdt_num = 0     # Para registrar onde foi o último D-AMDT (para o alerta)\n",
    "\n",
    "        idx = 0\n",
    "        while idx < len(texto_completo):\n",
    "            linha = texto_completo[idx].strip()\n",
    "\n",
    "            # Detecta o início de um novo aeroporto\n",
    "            if linha.startswith(\"D-AMDT\"):\n",
    "                # Salva o bloco anterior, se existir\n",
    "                if codigo_oaci and aeroporto_info:\n",
    "                    dados_aeroportos.append({\n",
    "                        \"codigo_aeroporto\": codigo_oaci,\n",
    "                        \"infos_rotaer\": \"\\n\".join(aeroporto_info)\n",
    "                    })\n",
    "\n",
    "                capturando = True\n",
    "                aeroporto_info = []\n",
    "                codigo_oaci = None\n",
    "                linhas_espera_oaci = 8  # Vamos procurar o OACI nas próximas 8 linhas\n",
    "                linha_damdt_num = idx + 1  # Guardar o número da linha (contagem humana começa em 1)\n",
    "\n",
    "            elif capturando and not codigo_oaci and linhas_espera_oaci > 0:\n",
    "                # Preparar linha atual + próxima para capturar quebras de linha no título\n",
    "                linha_atual = linha\n",
    "                linha_proxima = texto_completo[idx + 1].strip() if (idx + 1) < len(texto_completo) else \"\"\n",
    "                linha_combinada = linha_atual + \" \" + linha_proxima\n",
    "\n",
    "                match = re.search(regex_oaci, linha_combinada)\n",
    "                if match:\n",
    "                    codigo_oaci = match.group(1)\n",
    "                    # print(f\"[INFO] OACI encontrado: {codigo_oaci} nas linhas {idx+1} e {idx+2}\")\n",
    "\n",
    "                linhas_espera_oaci -= 1\n",
    "\n",
    "                if linhas_espera_oaci == 0 and not codigo_oaci:\n",
    "                    print(f\"[ALERTA] Não encontrou OACI no bloco iniciado com D-AMDT na linha {linha_damdt_num}.\")\n",
    "\n",
    "            elif capturando:\n",
    "                # Apenas armazena o texto no bloco de informações\n",
    "                aeroporto_info.append(linha)\n",
    "\n",
    "            idx += 1  # Avança para a próxima linha\n",
    "\n",
    "        # Salvar o último bloco se tiver informações\n",
    "        if codigo_oaci and aeroporto_info:\n",
    "            dados_aeroportos.append({\n",
    "                \"codigo_aeroporto\": codigo_oaci,\n",
    "                \"infos_rotaer\": \"\\n\".join(aeroporto_info)\n",
    "            })\n",
    "\n",
    "        df_aeroportos = pd.DataFrame(dados_aeroportos)\n",
    "        return df_aeroportos\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "# Nome do arquivo PDF\n",
    "nome_arquivo = \"data/pdf/rotaer_completo.pdf\"\n",
    "\n",
    "df_aeroportos2 = extrair_dados_pdf(nome_arquivo)\n",
    "\n",
    "# Mostrar um resumo dos códigos encontrados\n",
    "if df_aeroportos2 is not None:\n",
    "    print(\"\\nResumo dos códigos capturados:\")\n",
    "    print(df_aeroportos2['codigo_aeroporto'].value_counts())\n",
    "\n",
    "    # Para validar rapidamente\n",
    "    if \"SBGR\" in df_aeroportos2['codigo_aeroporto'].values:\n",
    "        print(\"\\n✅ SBGR foi capturado com sucesso!\")\n",
    "    else:\n",
    "        print(\"\\n❌ SBGR ainda não foi encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\AppData\\Local\\Temp\\ipykernel_11528\\415894066.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_aeroportos2['infos_rotaer'].str.contains(r'\\b(RDONAV|RFFS)\\b', flags=re.IGNORECASE, na=False)\n"
     ]
    }
   ],
   "source": [
    "#Criar df apenas com os aeroportos que possuem RDONAV ou RFFS\n",
    "\n",
    "# Filtrar as linhas onde a coluna 'infos_rotaer' contém \"RDONAV\" ou \"RFFS\"\n",
    "aero_base = df_aeroportos2[\n",
    "    df_aeroportos2['infos_rotaer'].str.contains(r'\\b(RDONAV|RFFS)\\b', flags=re.IGNORECASE, na=False)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     codigo_aeroporto                                       infos_rotaer\n",
      "435              SBAE  22 09 28S/049 04 06W\\nAD PUB REDE VOA 18SE UTC...\n",
      "599              SBAF  Campo Délio Jardim de Mattos ( SBAF ) / RIO DE...\n",
      "607              SBAN  Campo Marechal Márcio de Souza e Mello ( SBAN ...\n",
      "5654             SBAR  Santa Maria ( SBAR ) / ARACAJU, SE\\n10 59 07S/...\n",
      "5228             SBAT  Piloto Osvaldo Marques Dias ( SBAT ) / ALTA\\nF...\n",
      "...               ...                                                ...\n",
      "4660             SWLB  07 16 44S/064 46 10W\\nAD PUB 4SE UTC-5 HJ\\n74 ...\n",
      "5154             SWPI  PARINTINS ( SWPI ) / PARINTINS, AM\\n02 40 25S/...\n",
      "5229             SWPM  11 38 29S/061 10 44W\\nAD PUB 4S UTC-4 VFR L21 ...\n",
      "5937             SWTS  TANGARA DA SERRA ( SWTS ) / TANGARÁ DA SERRA,\\...\n",
      "531              SWUZ  LUZIÂNIA, GO\\n16 15 42S/047 58 07W\\nAD PUB INF...\n",
      "\n",
      "[146 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ordenar opcionalmente para garantir consistência (ex: ordem alfabética)\n",
    "aero_base = aero_base.sort_values(by='codigo_aeroporto')\n",
    "\n",
    "# Remover duplicatas com base no código OACI, mantendo apenas o primeiro\n",
    "aero_base_semduplicado = aero_base.drop_duplicates(subset='codigo_aeroporto', keep='first')\n",
    "\n",
    "# Exibir o DataFrame final sem duplicações\n",
    "print(aero_base_semduplicado)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     codigo_aeroporto             RFFS\n",
      "435              SBAE             None\n",
      "599              SBAF    - CAT MIL - 6\n",
      "607              SBAN    - CAT MIL - 6\n",
      "5654             SBAR  - CAT CIVIL - 7\n",
      "5228             SBAT             None\n",
      "...               ...              ...\n",
      "4660             SWLB             None\n",
      "5154             SWPI  - CAT CIVIL - 5\n",
      "5229             SWPM  - CAT CIVIL - 5\n",
      "5937             SWTS             None\n",
      "531              SWUZ             None\n",
      "\n",
      "[146 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Extrair os dados de Ctegoria Contra Incendio a partir do filtro do termo \"RFFS\"\n",
    "\n",
    "def extrair_rffs(texto):\n",
    "    \"\"\"\n",
    "    Função para extrair corretamente 'RFFS' seguido de:\n",
    "    - 'CAT CIVIL - número' (sempre)\n",
    "    - '[X] CAT CIVIL - número' (se houver número antes entre colchetes)\n",
    "    - 'CAT MILITAR - número' (se existir)\n",
    "    - Mantém apenas essas informações, removendo qualquer coisa extra\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):  # Se o valor for NaN, retorna None\n",
    "        return None\n",
    "\n",
    "    # Expressão regular aprimorada para capturar o necessário\n",
    "    match = re.search(r'RFFS\\s*([\\[\\]\\w\\s-]*\\d+)', texto, re.IGNORECASE)  # Agora inclui colchetes `[]`\n",
    "\n",
    "    if match:\n",
    "        return match.group(1).strip()  # Retorna apenas o conteúdo desejado\n",
    "\n",
    "    return None  # Retorna None se não encontrar nada válido\n",
    "\n",
    "# Criar nova base `aero_base_rffs2`\n",
    "aero_base_rffs = aero_base_semduplicado.copy()\n",
    "aero_base_rffs['RFFS'] = aero_base_rffs['infos_rotaer'].apply(extrair_rffs)\n",
    "\n",
    "# Exibir os primeiros resultados para conferência\n",
    "print(aero_base_rffs[['codigo_aeroporto', 'RFFS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas de auxílios\n",
    "auxilios_radio = [\"VOR\", \"DME\", \"VORTAC\", \"TACAN\", \"NDB\", \"LMM\", \"LOM\", \"ILS\", \"LOC\", \"GS\", \"IM\", \"MM\", \"OM\"]\n",
    "pares_auxilios = [\"ILS/DME\", \"VOR/DME\", \"LOC/DME\"]\n",
    "\n",
    "def extrair_auxilios_por_etapa(texto):\n",
    "    texto = texto.upper()\n",
    "    texto = texto.replace('\\n', ' ').replace('\\xa0', ' ')\n",
    "    texto = re.sub(r'\\s+', ' ', texto)\n",
    "\n",
    "    # Normalização de pares quebrados\n",
    "    texto = re.sub(r\"I\\s*L\\s*S\\s*/\\s*D\\s*M\\s*E\", \"ILS/DME\", texto)\n",
    "    texto = re.sub(r\"V\\s*O\\s*R\\s*/\\s*D\\s*M\\s*E\", \"VOR/DME\", texto)\n",
    "    texto = re.sub(r\"L\\s*O\\s*C\\s*/\\s*D\\s*M\\s*E\", \"LOC/DME\", texto)\n",
    "\n",
    "    pos_rdonav = texto.find(\"RDONAV\")\n",
    "    if pos_rdonav == -1:\n",
    "        return None, None\n",
    "\n",
    "    # Limitar a leitura a 100 caracteres após \"RDONAV\"\n",
    "    trecho = texto[pos_rdonav:pos_rdonav + 300]\n",
    "    pares_detectados = []\n",
    "    usados = set()\n",
    "\n",
    "    # Etapa 1 – detectar pares exatos e registrar apenas o par como 'usado'\n",
    "    for par in pares_auxilios:\n",
    "        pattern = r'(?<![A-Z])' + re.escape(par) + r'(?![A-Z])'\n",
    "        matches = list(re.finditer(pattern, trecho))\n",
    "        for match in matches:\n",
    "            pares_detectados.append(match.group())\n",
    "            usados.add(par)  # Adiciona apenas o par completo\n",
    "        trecho = re.sub(pattern, 'xxx', trecho)\n",
    "\n",
    "    # Etapa 2 – detectar auxílios isolados mesmo que tenham sido parte de um par\n",
    "    auxilios_individuais = []\n",
    "    for aux in auxilios_radio:\n",
    "        pattern = r'(?<![A-Z])' + re.escape(aux) + r'(?![A-Z])'\n",
    "        if re.search(pattern, trecho):\n",
    "            auxilios_individuais.append(aux)\n",
    "            trecho = re.sub(pattern, 'xxx', trecho)\n",
    "\n",
    "    return \"\\n\".join(pares_detectados) if pares_detectados else None, \\\n",
    "           \"\\n\".join(auxilios_individuais) if auxilios_individuais else None\n",
    "\n",
    "# Aplicar a função nas colunas\n",
    "aero_base_rffs[[\"Auxilios_Pares\", \"Auxilios_Individuais\"]] = aero_base_rffs[\"infos_rotaer\"].apply(\n",
    "    lambda x: pd.Series(extrair_auxilios_por_etapa(x))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novo DataFrame final chamado 'base_rotaer_final'\n",
    "base_rotaer = aero_base_rffs.copy()\n",
    "\n",
    "# Salvar o DataFrame final em CSV\n",
    "base_rotaer.to_csv(\"data/csv/base_rotaer.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover linhas duplicadas (de RDONAV) mantendo a ordem\n",
    "def limpar_auxilios(celula):\n",
    "    if pd.isna(celula):\n",
    "        return None\n",
    "    linhas = celula.strip().split('\\n')\n",
    "    vistos = set()\n",
    "    resultado = []\n",
    "    for linha in linhas:\n",
    "        if linha not in vistos:\n",
    "            resultado.append(linha)\n",
    "            vistos.add(linha)\n",
    "    return '\\n'.join(resultado)\n",
    "\n",
    "# Aplica a limpeza nas colunas\n",
    "base_rotaer[\"Auxilios_Pares\"] = base_rotaer[\"Auxilios_Pares\"].apply(limpar_auxilios)\n",
    "base_rotaer[\"Auxilios_Individuais\"] = base_rotaer[\"Auxilios_Individuais\"].apply(limpar_auxilios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- Função 1: Limpeza e extração dos padrões CAT -----------\n",
    "\n",
    "def limpar_rffs(texto):\n",
    "    \"\"\"\n",
    "    Extrai apenas:\n",
    "    - CAT CIVIL - (1 a 10)\n",
    "    - CAT MILITAR - (1 a 10)\n",
    "    - CAT MIL (1 a 10)\n",
    "    - CAT - (1 a 10)\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return None\n",
    "\n",
    "    # Regex corrigida para incluir 10 corretamente\n",
    "    match = re.findall(\n",
    "        r'(CAT\\s*CIVIL\\s*-\\s*(?:10|[1-9])|CAT\\s*MILITAR\\s*-\\s*(?:10|[1-9])|CAT\\s*MIL\\s*(?:10|[1-9])|CAT\\s*-\\s*(?:10|[1-9]))',\n",
    "        texto,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    if match:\n",
    "        return \" / \".join(match)\n",
    "    else:\n",
    "        return texto  # Retorna o original se nada for extraído\n",
    "\n",
    "# ----------- Função 2: Padronização dos termos -----------\n",
    "\n",
    "def padronizar_rffs(texto):\n",
    "    \"\"\"\n",
    "    Padroniza os nomes:\n",
    "    - \"CAT - n\" → \"CAT CIVIL n\"\n",
    "    - \"CAT MIL n\" → \"CAT MILITAR n\"\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return None\n",
    "\n",
    "    # \"CAT - 10\" ou \"CAT - 1\" → \"CAT CIVIL 10\" ou \"CAT CIVIL 1\"\n",
    "    texto = re.sub(r'CAT\\s*-\\s*(10|[1-9])', r'CAT CIVIL \\1', texto, flags=re.IGNORECASE)\n",
    "\n",
    "    # \"CAT MIL 10\" ou \"CAT MIL 1\" → \"CAT MILITAR 10\"\n",
    "    texto = re.sub(r'CAT\\s*MIL\\s*(10|[1-9])', r'CAT MILITAR \\1', texto, flags=re.IGNORECASE)\n",
    "\n",
    "    return texto\n",
    "\n",
    "# ----------- Aplicando ao DataFrame -----------\n",
    "\n",
    "# Aplicar função de limpeza\n",
    "base_rotaer['RFFS'] = base_rotaer['RFFS'].apply(limpar_rffs)\n",
    "\n",
    "# Aplicar padronização\n",
    "base_rotaer['RFFS'] = base_rotaer['RFFS'].apply(padronizar_rffs)\n",
    "\n",
    "base_rotaer.to_csv(\"output/base_rotaer_final.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
